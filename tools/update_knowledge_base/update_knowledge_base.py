#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –Ω–æ–≤–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤ Vanessa Automation

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json
    python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json --output-dir ai-knowledge/
    python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json --dry-run
"""

import json
import sys
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Any


class KnowledgeBaseUpdater:
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π AI –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤ Vanessa"""
    
    def __init__(self, source_file: str, output_dir: str = None, dry_run: bool = False):
        self.source_file = Path(source_file)
        self.output_dir = Path(output_dir) if output_dir else Path('ai-knowledge')
        self.data_dir = Path('data')
        self.dry_run = dry_run
        
        self.stats = {
            'total_steps': 0,
            'categories': 0,
            'subcategories': 0,
            'new_steps': 0,
            'updated_steps': 0,
            'removed_steps': 0
        }
        
        self.library_data = []
        self.old_knowledge = {}
    
    def log(self, message: str, level: str = 'INFO'):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        prefix = {
            'INFO': '‚úì',
            'WARN': '‚ö†',
            'ERROR': '‚úó',
            'DRY': 'üîç',
            'SUCCESS': '‚úÖ'
        }.get(level, '¬∑')
        
        print(f"{prefix} {message}")
    
    def load_source_library(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤"""
        if not self.source_file.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {self.source_file}")
        
        self.log(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–∑ {self.source_file}...")
        
        try:
            with open(self.source_file, 'r', encoding='utf-8') as f:
                self.library_data = json.load(f)
            
            self.stats['total_steps'] = len(self.library_data)
            self.log(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {self.stats['total_steps']} —à–∞–≥–æ–≤", 'SUCCESS')
            
        except json.JSONDecodeError as e:
            raise Exception(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        except Exception as e:
            raise Exception(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
    
    def load_old_knowledge(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
        old_file = self.output_dir / 'steps-library.json'
        
        if not old_file.exists():
            self.log("–°—Ç–∞—Ä–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (–ø–µ—Ä–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ)", 'WARN')
            return
        
        try:
            with open(old_file, 'r', encoding='utf-8') as f:
                self.old_knowledge = json.load(f)
            
            old_count = sum(len(steps) for steps in self.old_knowledge.values())
            self.log(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è –±–∞–∑–∞: {old_count} —à–∞–≥–æ–≤")
            
        except Exception as e:
            self.log(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–∞—Ä—É—é –±–∞–∑—É: {e}", 'WARN')
    
    def create_ai_knowledge_base(self) -> Dict[str, List[Dict]]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è AI
        –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –æ—Å–Ω–æ–≤–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        self.log("\n–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è AI...")
        
        knowledge_base = defaultdict(list)
        
        for step in self.library_data:
            step_type = step.get('–ü–æ–ª–Ω—ã–π–¢–∏–ø–®–∞–≥–∞', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            if '.' in step_type:
                main_category = step_type.split('.')[0]
            else:
                main_category = step_type
            
            # –î–æ–±–∞–≤–ª—è–µ–º —à–∞–≥ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é
            knowledge_base[main_category].append({
                "—à–∞–≥": step.get('–ò–º—è–®–∞–≥–∞', ''),
                "–æ–ø–∏—Å–∞–Ω–∏–µ": step.get('–û–ø–∏—Å–∞–Ω–∏–µ–®–∞–≥–∞', ''),
                "—Ç–∏–ø": step_type
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —à–∞–≥–æ–≤
        sorted_kb = dict(sorted(
            knowledge_base.items(),
            key=lambda x: len(x[1]),
            reverse=True
        ))
        
        self.stats['categories'] = len(sorted_kb)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        subcategories = set()
        for step in self.library_data:
            step_type = step.get('–ü–æ–ª–Ω—ã–π–¢–∏–ø–®–∞–≥–∞', '')
            if '.' in step_type:
                subcategories.add(step_type)
        self.stats['subcategories'] = len(subcategories)
        
        return sorted_kb
    
    def compare_with_old(self, new_kb: Dict):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —Å—Ç–∞—Ä–æ–π –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π"""
        if not self.old_knowledge:
            self.log("–ù–µ—Ç —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", 'WARN')
            return
        
        self.log("\n–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π...")
        
        # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —à–∞–≥–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        old_steps = set()
        for category, steps in self.old_knowledge.items():
            for step in steps:
                old_steps.add(step['—à–∞–≥'])
        
        new_steps = set()
        for category, steps in new_kb.items():
            for step in steps:
                new_steps.add(step['—à–∞–≥'])
        
        # –ù–∞—Ö–æ–¥–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        added = new_steps - old_steps
        removed = old_steps - new_steps
        
        self.stats['new_steps'] = len(added)
        self.stats['removed_steps'] = len(removed)
        
        if added:
            self.log(f"–ù–æ–≤—ã—Ö —à–∞–≥–æ–≤: {len(added)}", 'INFO')
            if len(added) <= 10:
                for step in list(added)[:10]:
                    self.log(f"  + {step[:80]}...", 'INFO')
        
        if removed:
            self.log(f"–£–¥–∞–ª–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤: {len(removed)}", 'WARN')
            if len(removed) <= 10:
                for step in list(removed)[:10]:
                    self.log(f"  - {step[:80]}...", 'WARN')
    
    def generate_statistics(self, knowledge_base: Dict) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
        stats = {
            "version": "1.0",
            "updated_at": datetime.now().isoformat(),
            "total_steps": self.stats['total_steps'],
            "total_categories": self.stats['categories'],
            "total_subcategories": self.stats['subcategories'],
            "categories": {}
        }
        
        for category, steps in knowledge_base.items():
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤ —ç—Ç–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            subcats = set()
            for step in steps:
                step_type = step['—Ç–∏–ø']
                if '.' in step_type:
                    parts = step_type.split('.')
                    if len(parts) > 1:
                        subcats.add('.'.join(parts[1:]))
            
            stats["categories"][category] = {
                "steps_count": len(steps),
                "subcategories_count": len(subcats),
                "subcategories": sorted(list(subcats))
            }
        
        return stats
    
    def save_files(self, knowledge_base: Dict, statistics: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
        
        if self.dry_run:
            self.log("\nüîç –†–ï–ñ–ò–ú –ü–†–ï–î–ü–†–û–°–ú–û–¢–†–ê - —Ñ–∞–π–ª—ã –ù–ï –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã", 'DRY')
            return
        
        self.log("\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è AI
        ai_kb_file = self.output_dir / 'steps-library.json'
        with open(ai_kb_file, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, ensure_ascii=False, indent=2)
        
        size_kb = ai_kb_file.stat().st_size / 1024
        self.log(f"‚úì {ai_kb_file} ({size_kb:.0f} KB)", 'SUCCESS')
        
        # 2. –ö–æ–ø–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É –≤ data/
        full_lib_file = self.data_dir / 'library-full.json'
        with open(full_lib_file, 'w', encoding='utf-8') as f:
            json.dump(self.library_data, f, ensure_ascii=False, indent=2)
        
        size_kb = full_lib_file.stat().st_size / 1024
        self.log(f"‚úì {full_lib_file} ({size_kb:.0f} KB)", 'SUCCESS')
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = self.data_dir / 'statistics.json'
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, ensure_ascii=False, indent=2)
        
        self.log(f"‚úì {stats_file}", 'SUCCESS')
        
        # 4. –°–æ–∑–¥–∞–µ–º README –¥–ª—è ai-knowledge
        self.create_ai_knowledge_readme(statistics)
        
        # 5. –û–±–Ω–æ–≤–ª—è–µ–º README –¥–ª—è data
        self.create_data_readme(statistics)
    
    def create_ai_knowledge_readme(self, stats: Dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README –¥–ª—è ai-knowledge"""
        readme_file = self.output_dir / 'README.md'
        
        content = f"""# –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è AI

## üì• –ß—Ç–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤ AI

–ó–∞–≥—Ä—É–∑–∏—Ç–µ —ç—Ç–∏ **3 —Ñ–∞–π–ª–∞** –≤ –≤–∞—à AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç:

1. ‚úÖ `guide.md` (27 KB) - –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –¥–ª—è AI
2. ‚úÖ `templates.md` (31 KB) - –®–∞–±–ª–æ–Ω—ã —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤  
3. ‚úÖ `steps-library.json` (655 KB) - –ë–∞–∑–∞ –∏–∑ {stats['total_steps']} —à–∞–≥–æ–≤

**–ò—Ç–æ–≥–æ:** ~715 KB

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏

**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {datetime.now().strftime('%d.%m.%Y %H:%M')}

- **–í—Å–µ–≥–æ —à–∞–≥–æ–≤:** {stats['total_steps']}
- **–ö–∞—Ç–µ–≥–æ—Ä–∏–π:** {stats['total_categories']}
- **–ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π:** {stats['total_subcategories']}

### –¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —à–∞–≥–æ–≤

"""
        
        # –¢–æ–ø-10 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        sorted_categories = sorted(
            stats['categories'].items(),
            key=lambda x: x[1]['steps_count'],
            reverse=True
        )
        
        for i, (category, cat_stats) in enumerate(sorted_categories[:10], 1):
            content += f"{i}. **{category}** - {cat_stats['steps_count']} —à–∞–≥–æ–≤ "
            content += f"({cat_stats['subcategories_count']} –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π)\n"
        
        content += """
## ü§ñ –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å

- ‚úÖ Claude (Anthropic) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
- ‚úÖ ChatGPT (OpenAI)
- ‚úÖ Gemini (Google)
- ‚úÖ –î—Ä—É–≥–∏–µ LLM

## üìñ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ 3 —Ñ–∞–π–ª–∞ –≤ —á–∞—Ç —Å AI
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ–º–ø—Ç –∏–∑ `/templates/prompts/`
3. –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–∏!

[–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è ‚Üí](../docs/quick-start.md)

---

**–í–µ—Ä—Å–∏—è:** {stats['version']}  
**–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {stats['updated_at'][:10]}
"""
        
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.log(f"‚úì {readme_file}", 'SUCCESS')
    
    def create_data_readme(self, stats: Dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ README –¥–ª—è data"""
        readme_file = self.data_dir / 'README.md'
        
        content = f"""# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

## üìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ

### library-full.json
–ü–æ–ª–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ —à–∞–≥–æ–≤ –∏–∑ Vanessa Automation –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.

- **–†–∞–∑–º–µ—Ä:** ~680 KB
- **–§–æ—Ä–º–∞—Ç:** JSON –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤
- **–®–∞–≥–æ–≤:** {stats['total_steps']}
- **–û–±–Ω–æ–≤–ª–µ–Ω–æ:** {datetime.now().strftime('%d.%m.%Y')}

### statistics.json
–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ —à–∞–≥–æ–≤.

- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- –°–ø–∏—Å–æ–∫ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è

### steps-compact.md
–ö–æ–º–ø–∞–∫—Ç–Ω—ã–π —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —à–∞–≥–æ–≤.

- **–†–∞–∑–º–µ—Ä:** ~55 KB
- **–§–æ—Ä–º–∞—Ç:** Markdown
- –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

## üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ

–î–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–∑ Vanessa Automation:

```bash
python tools/update_knowledge_base.py path/to/–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json
```

## üìä –¢–µ–∫—É—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** {stats['updated_at'][:10]}

- –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {stats['total_steps']}
- –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {stats['total_categories']}
- –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π: {stats['total_subcategories']}

### –ö–∞—Ç–µ–≥–æ—Ä–∏–∏

"""
        
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        sorted_categories = sorted(
            stats['categories'].items(),
            key=lambda x: x[1]['steps_count'],
            reverse=True
        )
        
        for category, cat_stats in sorted_categories:
            content += f"- **{category}**: {cat_stats['steps_count']} —à–∞–≥–æ–≤\n"
        
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.log(f"‚úì {readme_file}", 'SUCCESS')
    
    def print_summary(self):
        """–í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self.log("\n" + "="*70)
        self.log("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        self.log("="*70 + "\n")
        
        mode = "–†–ï–ñ–ò–ú –ü–†–ï–î–ü–†–û–°–ú–û–¢–†–ê" if self.dry_run else "–û–ë–ù–û–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û"
        self.log(f"–†–µ–∂–∏–º: {mode}\n")
        
        self.log(f"üìä –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —à–∞–≥–æ–≤:")
        self.log(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {self.stats['total_steps']}")
        self.log(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {self.stats['categories']}")
        self.log(f"   –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π: {self.stats['subcategories']}")
        
        if self.old_knowledge:
            self.log(f"\nüîÑ –ò–∑–º–µ–Ω–µ–Ω–∏—è:")
            self.log(f"   –ù–æ–≤—ã—Ö —à–∞–≥–æ–≤: {self.stats['new_steps']}", 
                    'INFO' if self.stats['new_steps'] else 'INFO')
            self.log(f"   –£–¥–∞–ª–µ–Ω–Ω—ã—Ö —à–∞–≥–æ–≤: {self.stats['removed_steps']}", 
                    'WARN' if self.stats['removed_steps'] else 'INFO')
        
        if not self.dry_run:
            self.log(f"\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            self.log(f"   {self.output_dir}/steps-library.json (–¥–ª—è AI)")
            self.log(f"   {self.output_dir}/README.md")
            self.log(f"   {self.data_dir}/library-full.json")
            self.log(f"   {self.data_dir}/statistics.json")
            self.log(f"   {self.data_dir}/README.md")
        
        self.log("")
        
        if self.dry_run:
            self.log("–î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ –±–µ–∑ --dry-run", 'WARN')
        else:
            self.log("‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞!", 'SUCCESS')
            self.log("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
            self.log("1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã")
            self.log("2. –ó–∞–∫–æ–º–º–∏—Ç—å—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ Git")
            self.log("3. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ AI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        self.log("")
    
    def update(self):
        """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"""
        try:
            self.log("="*70)
            self.log("–û–ë–ù–û–í–õ–ï–ù–ò–ï –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô VANESSA AUTOMATION")
            self.log("="*70 + "\n")
            
            if self.dry_run:
                self.log("‚ö†Ô∏è  –†–ï–ñ–ò–ú –ü–†–ï–î–ü–†–û–°–ú–û–¢–†–ê", 'WARN')
                self.log("–ò–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\n")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            self.load_source_library()
            self.load_old_knowledge()
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
            knowledge_base = self.create_ai_knowledge_base()
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –≤–µ—Ä—Å–∏–µ–π
            self.compare_with_old(knowledge_base)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            statistics = self.generate_statistics(knowledge_base)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã
            self.save_files(knowledge_base, statistics)
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            self.print_summary()
            
            return True
            
        except Exception as e:
            self.log(f"–û—à–∏–±–∫–∞: {e}", 'ERROR')
            return False


def main():
    parser = argparse.ArgumentParser(
        description='–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤ Vanessa Automation',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
  python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json

  # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
  python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json --dry-run

  # –£–∫–∞–∑–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è ai-knowledge
  python update_knowledge_base.py –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json --output-dir ai-knowledge/

  # –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä
  python update_knowledge_base.py /path/to/–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json \\
      --output-dir ai-knowledge/ \\
      --dry-run

–§–∞–π–ª—ã –±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã:
  - ai-knowledge/steps-library.json (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –±–∞–∑–∞ –¥–ª—è AI)
  - ai-knowledge/README.md (–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è)
  - data/library-full.json (–ø–æ–ª–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞)
  - data/statistics.json (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
  - data/README.md (–æ–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö)
        '''
    )
    
    parser.add_argument(
        'source',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json'
    )
    
    parser.add_argument(
        '--output-dir',
        default='ai-knowledge',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è ai-knowledge (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ai-knowledge)'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='–†–µ–∂–∏–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π'
    )
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –∞–ø–¥–µ–π—Ç–µ—Ä –∏ –∑–∞–ø—É—Å–∫–∞–µ–º
    updater = KnowledgeBaseUpdater(
        source_file=args.source,
        output_dir=args.output_dir,
        dry_run=args.dry_run
    )
    
    success = updater.update()
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
