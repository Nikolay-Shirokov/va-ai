#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ Vanessa Automation

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
1. –í—Å–µ –ª–∏ —à–∞–≥–∏ –∏–∑ —Å—Ü–µ–Ω–∞—Ä–∏—è –µ—Å—Ç—å –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ —à–∞–≥–æ–≤
2. –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ Gherkin
3. –ù–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
4. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python validate_scenario.py scenario.feature
    python validate_scenario.py scenario.feature --library –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json
"""

import json
import re
import sys
import argparse
import os
from pathlib import Path
from typing import List, Dict, Tuple, Set
from difflib import SequenceMatcher, get_close_matches

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ –º–æ–¥—É–ª–∏ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
try:
    from step_parser import StepParser, ParsedStep
    from semantic_matcher import SemanticMatcher, SemanticMatch
    from metrics_logger import MetricsLogger
    SEMANTIC_ANALYSIS_AVAILABLE = True
except ImportError:
    SEMANTIC_ANALYSIS_AVAILABLE = False
    print("‚ö†Ô∏è –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ú–æ–¥—É–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == 'win32':
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent.parent
DEFAULT_LIBRARY = PROJECT_ROOT / 'data' / 'library-full.json'
METRICS_FILE = PROJECT_ROOT / 'data' / 'metrics.jsonl'


class Colors:
    """ANSI —Ü–≤–µ—Ç–∞ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞–ª–∞"""
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    MAGENTA = '\033[95m'
    CYAN = '\033[96m'
    WHITE = '\033[97m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'


class StepLibrary:
    """–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —à–∞–≥–æ–≤ Vanessa Automation"""
    
    def __init__(self, library_path: str, enable_semantic: bool = False):
        self.steps = []
        self.steps_normalized = {}  # –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —à–∞–≥ -> –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —à–∞–≥
        self.enable_semantic = enable_semantic and SEMANTIC_ANALYSIS_AVAILABLE
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä –∏ matcher –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if self.enable_semantic:
            self.parser = StepParser()
            self.matcher = SemanticMatcher()
        
        self.load_library(library_path)
    
    def load_library(self, path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤ –∏–∑ JSON"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±–æ–∏—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
            if isinstance(data, list):
                # –§–æ—Ä–º–∞—Ç –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json
                self.steps = [step.get('–ò–º—è–®–∞–≥–∞', '') for step in data]
            elif isinstance(data, dict):
                # –§–æ—Ä–º–∞—Ç vanessa_steps_ai_knowledge.json
                for category, steps in data.items():
                    for step in steps:
                        self.steps.append(step.get('—à–∞–≥', ''))
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —à–∞–≥–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            for step in self.steps:
                normalized = self.normalize_step(step)
                self.steps_normalized[normalized] = step
            
            print(f"{Colors.GREEN}‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.steps)} —à–∞–≥–æ–≤ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏{Colors.END}")
            
        except FileNotFoundError:
            print(f"{Colors.RED}‚úó –§–∞–π–ª –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}{Colors.END}")
            sys.exit(1)
        except json.JSONDecodeError as e:
            print(f"{Colors.RED}‚úó –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}{Colors.END}")
            sys.exit(1)
    
    @staticmethod
    def normalize_step(step: str) -> str:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —à–∞–≥–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.
        –î–ª—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤ (—Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏–ª–∏ docstring)
        –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞.
        –ó–∞–º–µ–Ω—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã.
        """
        # –î–ª—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã—Ö —à–∞–≥–æ–≤ –±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º
        first_line = step.split('\n')[0].strip()

        # –£–¥–∞–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–î–∞–Ω–æ, –ö–æ–≥–¥–∞, –¢–æ–≥–¥–∞, –ò, –¢–∞–∫–∂–µ, –ó–∞—Ç–µ–º)
        step = re.sub(r'^(–î–∞–Ω–æ|–ö–æ–≥–¥–∞|–¢–æ–≥–¥–∞|–ò|–¢–∞–∫–∂–µ|–ó–∞—Ç–µ–º|–ù–æ)\s+', '', first_line, flags=re.IGNORECASE)
        
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        step = step.lower()

        # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–µ—Ç–æ—á–∏–µ –≤ –∫–æ–Ω—Ü–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–µ –¥–ª—è —à–∞–≥–æ–≤ —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏
        if step.endswith(':'):
            step = step[:-1].strip()
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤ –¥–≤–æ–π–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
        step = re.sub(r'"[^"]*"', '"{}"', step)
        
        # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç –≤ –æ–¥–∏–Ω–∞—Ä–Ω—ã—Ö –∫–∞–≤—ã—á–∫–∞—Ö –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
        step = re.sub(r"'[^']*'", '"{}"', step)
        
        # –ó–∞–º–µ–Ω—è–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –∏–∑ JSON (\") –Ω–∞ –æ–±—ã—á–Ω—ã–µ
        step = step.replace('\\"', '"')
        
        # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ($–ò–º—è$) –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
        step = re.sub(r'\$[^$]+\$', '${}$', step)
        
        # –ó–∞–º–µ–Ω—è–µ–º —á–∏—Å–ª–∞ –Ω–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
        step = re.sub(r'\b\d+\b', '#', step)
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        step = re.sub(r'\s+', ' ', step)
        
        return step.strip()
    
    def find_step(self, step: str) -> Tuple[bool, str, List[str]]:
        """
        –ü–æ–∏—Å–∫ —à–∞–≥–∞ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–Ω–∞–π–¥–µ–Ω, —Ç–æ—á–Ω–æ–µ_—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –ø–æ—Ö–æ–∂–∏–µ_—à–∞–≥–∏)
        """
        normalized = self.normalize_step(step)
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if normalized in self.steps_normalized:
            return True, self.steps_normalized[normalized], []
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —à–∞–≥–∏
        similar = []
        for norm_step, orig_step in self.steps_normalized.items():
            ratio = SequenceMatcher(None, normalized, norm_step).ratio()
            if ratio > 0.7:  # –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ 70%
                similar.append((orig_step, ratio))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
        similar.sort(key=lambda x: x[1], reverse=True)
        similar_steps = [s[0] for s in similar[:5]]  # —Ç–æ–ø-5
        
        return False, "", similar_steps
    
    def find_step_with_semantic(self, step: str) -> Dict:
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è AI
        """
        normalized = self.normalize_step(step)
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if normalized in self.steps_normalized:
            return {
                'found': True,
                'exact_match': self.steps_normalized[normalized],
                'suggestions': []
            }
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —à–∞–≥–∏ —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º
        suggestions = []
        
        for norm_step, orig_step in self.steps_normalized.items():
            similarity = SequenceMatcher(None, normalized, norm_step).ratio()
            
            if similarity > 0.7:  # –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ 70%
                suggestion_data = {
                    'text': orig_step,
                    'similarity': round(similarity, 2)
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
                if self.enable_semantic:
                    try:
                        # –ü–∞—Ä—Å–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º—ã–π —à–∞–≥–∏
                        orig_parsed = self.parser.parse(step)
                        sugg_parsed = self.parser.parse(orig_step)
                        
                        # –ü—Ä–æ–≤–æ–¥–∏–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
                        semantic_match = self.matcher.compare(step, orig_step)
                        
                        suggestion_data['parsed'] = {
                            'action': sugg_parsed.action,
                            'element_type': sugg_parsed.element_type,
                            'context': sugg_parsed.context,
                            'params': sugg_parsed.params
                        }
                        
                        suggestion_data['semantic_match'] = semantic_match.to_dict()
                        suggestion_data['confidence'] = self.matcher.get_confidence_level(
                            semantic_match.confidence
                        )
                        
                    except Exception as e:
                        # –ï—Å–ª–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ
                        pass
                
                suggestions.append(suggestion_data)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ö–æ–∂–µ—Å—Ç–∏
        suggestions.sort(key=lambda x: x['similarity'], reverse=True)
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5
        return {
            'found': False,
            'exact_match': '',
            'suggestions': suggestions[:5]
        }


class ScenarioValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ Gherkin"""
    
    KEYWORDS = ['–î–∞–Ω–æ', '–ö–æ–≥–¥–∞', '–¢–æ–≥–¥–∞', '–ò', '–¢–∞–∫–∂–µ', '–ó–∞—Ç–µ–º', '–ù–æ']
    REQUIRED_HEADERS = ['# encoding:', '# language:']
    
    def __init__(self, library: StepLibrary, debug: bool = False, ai_enhanced: bool = False, logger: 'MetricsLogger' = None):
        self.library = library
        self.debug = debug
        self.ai_enhanced = ai_enhanced
        self.logger = logger
        self.errors = []
        self.warnings = []
        self.stats = {
            'total_steps': 0,
            'valid_steps': 0,
            'invalid_steps': 0,
            'scenarios': 0,
            'features': 0
        }
    
    def validate_file(self, filepath: str) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
        except FileNotFoundError:
            return {'error': f'–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}'}
        except UnicodeDecodeError:
            return {'error': '–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ UTF-8.'}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
        self._check_headers(lines)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª
        self._check_feature_block(lines)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —à–∞–≥–∏
        self._check_steps(lines)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        self._check_variables(lines)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∫–∞–≤—ã—á–µ–∫
        self._check_quotes(lines)
        
        return {
            'errors': self.errors,
            'warnings': self.warnings,
            'stats': self.stats
        }
    
    def _check_headers(self, lines: List[str]):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
        first_lines = '\n'.join(lines[:5])
        
        if '# encoding:' not in first_lines and '# -*- coding:' not in first_lines:
            self.errors.append({
                'line': 1,
                'type': 'header',
                'severity': 'auto_fix',
                'message': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç—Ä–æ–∫–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π',
                'suggestion': '–î–æ–±–∞–≤—å—Ç–µ –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞: # encoding: utf-8',
                'fix': 'add_encoding'
            })
        
        if '# language:' not in first_lines:
            self.errors.append({
                'line': 1,
                'type': 'header',
                'severity': 'auto_fix',
                'message': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç—Ä–æ–∫–∞ —Å —è–∑—ã–∫–æ–º',
                'suggestion': '–î–æ–±–∞–≤—å—Ç–µ –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞: # language: ru',
                'fix': 'add_language'
            })
    
    def _check_feature_block(self, lines: List[str]):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∞ –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª"""
        has_feature = False
        
        for i, line in enumerate(lines, 1):
            if line.strip().startswith('–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:'):
                has_feature = True
                self.stats['features'] += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ–ø–∏—Å–∞–Ω–∏–µ
                if len(line.strip()) <= len('–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:') + 1:
                    self.warnings.append({
                        'line': i,
                        'type': 'feature',
                        'message': '–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è',
                        'suggestion': '–î–æ–±–∞–≤—å—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:"'
                    })
            
            if line.strip().startswith('–°—Ü–µ–Ω–∞—Ä–∏–π:'):
                self.stats['scenarios'] += 1
        
        if not has_feature:
            self.errors.append({
                'line': 0,
                'type': 'structure',
                'message': '–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –±–ª–æ–∫ "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:"',
                'suggestion': '–î–æ–±–∞–≤—å—Ç–µ –±–ª–æ–∫ "–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:" –ø–µ—Ä–µ–¥ —Å—Ü–µ–Ω–∞—Ä–∏—è–º–∏'
            })
    
    def _check_steps(self, lines: List[str]):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —à–∞–≥–æ–≤, –≤–∫–ª—é—á–∞—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–µ"""
        in_scenario = False
        current_step_lines = []
        current_step_start_line = 0

        for i, line in enumerate(lines, 1):
            stripped = line.strip()

            is_keyword_line = any(stripped.startswith(kw) for kw in self.KEYWORDS)
            is_new_scenario = stripped.startswith(('–°—Ü–µ–Ω–∞—Ä–∏–π:', '–ö–æ–Ω—Ç–µ–∫—Å—Ç:', '–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:'))
            is_comment = stripped.startswith('#')
            is_empty = not stripped

            # –ï—Å–ª–∏ –º—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º –Ω–æ–≤—ã–π —à–∞–≥ –∏–ª–∏ –Ω–∞—á–∞–ª–æ –Ω–æ–≤–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è,
            # –∏ —É –Ω–∞—Å –µ—Å—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –ø—Ä–µ–¥—ã–¥—É—â–∏–π —à–∞–≥, —Ç–æ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –µ–≥–æ.
            if current_step_lines and (is_keyword_line or is_new_scenario):
                full_step = "\n".join(current_step_lines)
                self.stats['total_steps'] += 1
                self._validate_step(current_step_start_line, full_step)
                current_step_lines = []

            if is_new_scenario:
                in_scenario = not stripped.startswith('–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:')
                continue

            if not in_scenario or is_comment or is_empty:
                continue

            if is_keyword_line:
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —à–∞–≥
                current_step_start_line = i
                current_step_lines = [stripped]
            elif current_step_lines and (stripped.startswith('|') or stripped.startswith('"""')):
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —à–∞–≥ (—Ç–∞–±–ª–∏—Ü–∞ –∏–ª–∏ docstring)
                current_step_lines.append(stripped)

        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥ –≤ —Ñ–∞–π–ª–µ, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
        if current_step_lines:
            full_step = "\n".join(current_step_lines)
            self.stats['total_steps'] += 1
            self._validate_step(current_step_start_line, full_step)
    
    def _validate_step(self, line_num: int, step: str):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–≥–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω AI-enhanced —Ä–µ–∂–∏–º
        if self.ai_enhanced and self.library.enable_semantic:
            result = self.library.find_step_with_semantic(step)
            found = result['found']
            exact_match = result['exact_match']
            suggestions = result.get('suggestions', [])
        else:
            found, exact_match, similar = self.library.find_step(step)
            suggestions = [{'text': s} for s in similar]
        
        if found:
            self.stats['valid_steps'] += 1
            if self.debug:
                print(f"{Colors.BLUE}‚úì –®–∞–≥ –Ω–∞ —Å—Ç—Ä–æ–∫–µ {line_num} –Ω–∞–π–¥–µ–Ω:{Colors.END} {step.splitlines()[0]}")
                print(f"{Colors.GREEN}  ‚Ü≥ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ:{Colors.END} {exact_match.splitlines()[0]}")
        else:
            self.stats['invalid_steps'] += 1
            
            error_info = {
                'line': line_num,
                'type': 'step',
                'step': step,
                'message': '–®–∞–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ',
                'suggestion': ''
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º severity –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ª–∏—á–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–∞
            if not suggestions:
                error_info['severity'] = 'critical'
            elif self.ai_enhanced and suggestions:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                has_safe = any(
                    s.get('semantic_match', {}).get('is_safe', False)
                    for s in suggestions
                )
                error_info['severity'] = 'semantic_check_required' if has_safe else 'critical'
            else:
                error_info['severity'] = 'semantic_check_required'
            
            if suggestions:
                if self.ai_enhanced:
                    error_info['suggestions'] = suggestions
                else:
                    error_info['similar_steps'] = [s['text'] for s in suggestions]
                error_info['suggestion'] = f'–í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –∏–º–µ–ª–∏ –≤ –≤–∏–¥—É –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö —à–∞–≥–æ–≤'
            else:
                error_info['suggestion'] = '–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –Ω–∞–ø–∏—Å–∞–Ω–∏—è —à–∞–≥–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π —à–∞–≥ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏'
            
            # –î–æ–±–∞–≤–ª—è–µ–º parsed –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —à–∞–≥–∞ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω AI-enhanced
            if self.ai_enhanced and self.library.enable_semantic:
                try:
                    orig_parsed = self.library.parser.parse(step)
                    error_info['parsed'] = {
                        'action': orig_parsed.action,
                        'element_type': orig_parsed.element_type,
                        'context': orig_parsed.context,
                        'params': orig_parsed.params
                    }
                except:
                    pass
            
            self.errors.append(error_info)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏–µ, –µ—Å–ª–∏ –ª–æ–≥–≥–µ—Ä –≤–∫–ª—é—á–µ–Ω
            if self.logger:
                self.logger.log_event('step_not_found', error_info)
    
    def _check_variables(self, lines: List[str]):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"""
        used_vars = set()
        defined_vars = set()
        
        for i, line in enumerate(lines, 1):
            # –ò—â–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö ($–ò–º—è–ü–µ—Ä–µ–º–µ–Ω–Ω–æ–π$)
            used = re.findall(r'\$([^$]+)\$', line)
            for var in used:
                used_vars.add((var, i))
            
            # –ò—â–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–∑–∞–ø–æ–º–∏–Ω–∞—é ... –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é)
            if '–≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é' in line or '–∫–∞–∫' in line:
                defined = re.findall(r'–ø–µ—Ä–µ–º–µ–Ω–Ω—É—é "([^"]+)"', line)
                defined += re.findall(r'–∫–∞–∫ "([^"]+)"', line)
                for var in defined:
                    defined_vars.add(var)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        for var, line_num in used_vars:
            if var not in defined_vars:
                self.warnings.append({
                    'line': line_num,
                    'type': 'variable',
                    'message': f'–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è "${var}$" –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞',
                    'suggestion': f'–î–æ–±–∞–≤—å—Ç–µ —à–∞–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π "{var}" –ø–µ—Ä–µ–¥ –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º'
                })
    
    def _check_quotes(self, lines: List[str]):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–≤—ã—á–µ–∫"""
        for i, line in enumerate(lines, 1):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏
            if "'" in line and any(line.strip().startswith(kw) for kw in self.KEYWORDS):
                error_info = {
                    'line': i,
                    'type': 'syntax',
                    'severity': 'auto_fix',
                    'message': '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –≤–º–µ—Å—Ç–æ –¥–≤–æ–π–Ω—ã—Ö',
                    'suggestion': '–ó–∞–º–µ–Ω–∏—Ç–µ –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ \' –Ω–∞ –¥–≤–æ–π–Ω—ã–µ "',
                    'fix': 'replace_quotes'
                }
                self.errors.append(error_info)
                if self.logger:
                    self.logger.log_event('auto_fix_suggestion', error_info)


def print_report(result: Dict, verbose: bool = False):
    """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    print("\n" + "="*80)
    print(f"{Colors.BOLD}–û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò –°–¶–ï–ù–ê–†–ò–Ø{Colors.END}")
    print("="*80 + "\n")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = result['stats']
    print(f"{Colors.BOLD}üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:{Colors.END}")
    print(f"  –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–æ–≤: {stats['features']}")
    print(f"  –°—Ü–µ–Ω–∞—Ä–∏–µ–≤: {stats['scenarios']}")
    print(f"  –í—Å–µ–≥–æ —à–∞–≥–æ–≤: {stats['total_steps']}")
    print(f"  {Colors.GREEN}‚úì –í–∞–ª–∏–¥–Ω—ã—Ö —à–∞–≥–æ–≤: {stats['valid_steps']}{Colors.END}")
    print(f"  {Colors.RED}‚úó –ù–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —à–∞–≥–æ–≤: {stats['invalid_steps']}{Colors.END}")
    
    # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
    if stats['total_steps'] > 0:
        percent = (stats['valid_steps'] / stats['total_steps']) * 100
        bar_length = 40
        filled = int(bar_length * percent / 100)
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        color = Colors.GREEN if percent >= 90 else Colors.YELLOW if percent >= 70 else Colors.RED
        print(f"\n  {color}[{bar}] {percent:.1f}%{Colors.END}\n")
    
    # –û—à–∏–±–∫–∏
    errors = result['errors']
    if errors:
        print(f"{Colors.BOLD}{Colors.RED}‚ùå –û–®–ò–ë–ö–ò ({len(errors)}):{Colors.END}\n")
        
        for i, error in enumerate(errors, 1):
            print(f"{Colors.BOLD}{i}. –°—Ç—Ä–æ–∫–∞ {error['line']}: {error['message']}{Colors.END}")
            
            if error['type'] == 'step' and verbose:
                print(f"   {Colors.CYAN}–®–∞–≥: {error['step']}{Colors.END}")
            
            print(f"   {Colors.YELLOW}üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {error['suggestion']}{Colors.END}")
            
            if 'similar_steps' in error and error['similar_steps']:
                print(f"   {Colors.MAGENTA}–ü–æ—Ö–æ–∂–∏–µ —à–∞–≥–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏:{Colors.END}")
                for j, similar in enumerate(error['similar_steps'][:3], 1):
                    print(f"      {j}. {similar}")
            
            print()
    else:
        print(f"{Colors.GREEN}‚úì –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ!{Colors.END}\n")
    
    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
    warnings = result['warnings']
    if warnings:
        print(f"{Colors.BOLD}{Colors.YELLOW}‚ö†Ô∏è  –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø ({len(warnings)}):{Colors.END}\n")
        
        for i, warning in enumerate(warnings, 1):
            print(f"{Colors.BOLD}{i}. –°—Ç—Ä–æ–∫–∞ {warning['line']}: {warning['message']}{Colors.END}")
            print(f"   {Colors.YELLOW}üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {warning['suggestion']}{Colors.END}\n")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
    print("="*80)
    if not errors:
        print(f"{Colors.GREEN}{Colors.BOLD}‚úì –°–¶–ï–ù–ê–†–ò–ô –í–ê–õ–ò–î–ï–ù –ò –ì–û–¢–û–í –ö –ó–ê–ü–£–°–ö–£!{Colors.END}")
    else:
        print(f"{Colors.RED}{Colors.BOLD}‚úó –¢–†–ï–ë–£–ï–¢–°–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–û–ö{Colors.END}")
    print("="*80 + "\n")


def print_compact_report(result: Dict):
    """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤."""
    errors = result.get('errors', [])
    warnings = result.get('warnings', [])

    if not errors and not warnings:
        print("OK")
        return

    print("---")
    print("report:")
    if errors:
        print("  errors:")
        for error in errors:
            line = error.get('line', 0)
            step = error.get('step', '')
            message = error.get('message', '')
            
            # –î–ª—è –æ—à–∏–±–æ–∫ —à–∞–≥–æ–≤ –≤—ã–≤–æ–¥–∏–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª—É—á—à–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            if error['type'] == 'step' and error.get('similar_steps'):
                print(f"    - line: {line}")
                print(f"      step: \"{step}\"")
                print(f"      suggestions:")
                for suggestion in error['similar_steps'][:3]:
                    print(f"        - \"{suggestion}\"")
            else: # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –æ—à–∏–±–æ–∫ - –ø—Ä–æ—Å—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ
                print(f"    - line: {line}")
                print(f"      step: \"{step}\"")
                print(f"      error: \"{message}\"")
                print(f"      fix: \"{error.get('suggestion', '')}\"")

    if warnings:
        print("  warnings:")
        for warning in warnings:
            line = warning.get('line', 0)
            message = warning.get('message', '')
            print(f"    - line: {line}")
            print(f"      warning: \"{message}\"")
            print(f"      fix: \"{warning.get('suggestion', '')}\"")
    print("---")


def print_ai_enhanced_report(result: Dict):
    """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ YAML –¥–ª—è AI"""
    import yaml
    
    errors = result.get('errors', [])
    warnings = result.get('warnings', [])
    
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã YAML
    clean_errors = []
    for error in errors:
        # –ö–æ–ø–∏—Ä—É–µ–º —á—Ç–æ–±—ã –Ω–µ –∏–∑–º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
        err_copy = error.copy()
        
        # –£–¥–∞–ª—è–µ–º –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –≤ AI-–æ—Ç—á–µ—Ç–µ
        err_copy.pop('message', None)
        err_copy.pop('suggestion', None)
        err_copy.pop('similar_steps', None)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 'text' –≤ suggestions –µ—Å–ª–∏ –Ω–µ—Ç —Å–µ–º–∞–Ω—Ç–∏–∫–∏
        if 'suggestions' in err_copy and err_copy['suggestions']:
            if 'semantic_match' not in err_copy['suggestions'][0]:
                err_copy['suggestions'] = [s['text'] for s in err_copy['suggestions']]
        
        clean_errors.append(err_copy)
        
    report = {
        'report': {
            'errors': clean_errors,
            'warnings': warnings,
            'stats': result.get('stats', {})
        }
    }
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º yaml –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –≤—ã–≤–æ–¥–∞
    # allow_unicode=True –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    # sort_keys=False –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
    print("---")
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å PyYAML –µ—Å–ª–∏ –æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
        print(yaml.dump(report, allow_unicode=True, sort_keys=False, indent=2))
    except ImportError:
        # –ï—Å–ª–∏ –Ω–µ—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º json.dumps —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏
        print(json.dumps(report, ensure_ascii=False, indent=2))
    except Exception as e:
        # –ù–∞ —Å–ª—É—á–∞–π –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        print(json.dumps(report, ensure_ascii=False, indent=2))
        
    print("---")


def print_recommendations_for_ai(result: Dict):
    """–í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    errors = result['errors']
    
    if not errors:
        print(f"\n{Colors.GREEN}–í—Å–µ —à–∞–≥–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã! –°—Ü–µ–Ω–∞—Ä–∏–π –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å.{Colors.END}\n")
        return
    
    print(f"\n{Colors.BOLD}üìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø AI-–ê–°–°–ò–°–¢–ï–ù–¢–ê:{Colors.END}\n")
    print("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:\n")
    
    step_errors = [e for e in errors if e['type'] == 'step']
    
    if step_errors:
        print(f"{Colors.RED}–®–∞–≥–∏, –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ:{Colors.END}\n")
        
        for i, error in enumerate(step_errors, 1):
            print(f"{i}. –°—Ç—Ä–æ–∫–∞ {error['line']}:")
            print(f"   ‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —à–∞–≥: {error['step']}")
            
            if 'similar_steps' in error and error['similar_steps']:
                print(f"   ‚úÖ –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –æ–¥–∏–Ω –∏–∑ —ç—Ç–∏—Ö —à–∞–≥–æ–≤:")
                for j, similar in enumerate(error['similar_steps'][:2], 1):
                    print(f"      {j}) {similar}")
            else:
                print(f"   ‚ö†Ô∏è  –ü–æ—Ö–æ–∂–∏—Ö —à–∞–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –í—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π –ø–æ–¥—Ö–æ–¥ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏.")
            print()
    
    other_errors = [e for e in errors if e['type'] != 'step']
    if other_errors:
        print(f"{Colors.YELLOW}–î—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:{Colors.END}\n")
        for error in other_errors:
            print(f"‚Ä¢ {error['message']} (—Å—Ç—Ä–æ–∫–∞ {error['line']})")
            print(f"  –†–µ—à–µ–Ω–∏–µ: {error['suggestion']}\n")


def main():
    parser = argparse.ArgumentParser(
        description='–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ Vanessa Automation',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python validate_scenario.py scenario.feature
  python validate_scenario.py scenario.feature --library –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json
  python validate_scenario.py scenario.feature --verbose --ai-format
        """
    )
    
    parser.add_argument('scenario', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å—Ü–µ–Ω–∞—Ä–∏—è (.feature)')
    parser.add_argument(
        '--library', '-l',
        default=str(DEFAULT_LIBRARY),
        help=f'–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —à–∞–≥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {DEFAULT_LIBRARY})'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥'
    )
    parser.add_argument(
        '--ai-format',
        action='store_true',
        help='–í—ã–≤–æ–¥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞'
    )
    parser.add_argument(
        '--ai-enhanced',
        action='store_true',
        help='–í—ã–≤–æ–¥ –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–º YAML-—Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è AI —Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º'
    )
    parser.add_argument(
        '--compact', '-c',
        action='store_true',
        help='–í—ã–≤–æ–¥ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤)'
    )
    parser.add_argument(
        '--debug',
        action='store_true',
        help='–í–∫–ª—é—á–∞–µ—Ç —Ä–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏ —Å –≤—ã–≤–æ–¥–æ–º –∫–∞–∂–¥–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —à–∞–≥–∞'
    )
    parser.add_argument(
        '--log-metrics',
        action='store_true',
        help='–í–∫–ª—é—á–∞–µ—Ç –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ data/metrics.jsonl'
    )
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
    if not Path(args.scenario).exists():
        print(f"{Colors.RED}‚úó –§–∞–π–ª —Å—Ü–µ–Ω–∞—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.scenario}{Colors.END}")
        sys.exit(1)
    
    if not Path(args.library).exists():
        print(f"{Colors.RED}‚úó –§–∞–π–ª –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.library}{Colors.END}")
        print(f"{Colors.YELLOW}–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --library –¥–ª—è —É–∫–∞–∑–∞–Ω–∏—è –ø—É—Ç–∏ –∫ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞–®–∞–≥–æ–≤.json{Colors.END}")
        sys.exit(1)
    
    print(f"\n{Colors.BOLD}–í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ü–µ–Ω–∞—Ä–∏—è: {args.scenario}{Colors.END}")
    print(f"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ —à–∞–≥–æ–≤: {args.library}\n")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–≥–µ—Ä, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    logger = None
    if args.log_metrics and SEMANTIC_ANALYSIS_AVAILABLE:
        logger = MetricsLogger(METRICS_FILE)
        print(f"üìù –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤–∫–ª—é—á–µ–Ω–æ. –§–∞–π–ª: {METRICS_FILE}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫—É —Å —É—á–µ—Ç–æ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    library = StepLibrary(args.library, enable_semantic=args.ai_enhanced)
    
    # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π
    validator = ScenarioValidator(library, debug=args.debug, ai_enhanced=args.ai_enhanced, logger=logger)
    result = validator.validate_file(args.scenario)
    
    if 'error' in result:
        print(f"{Colors.RED}‚úó –û—à–∏–±–∫–∞: {result['error']}{Colors.END}")
        sys.exit(1)
    
    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    if args.ai_enhanced:
        print_ai_enhanced_report(result)
    elif args.compact:
        print_compact_report(result)
    elif args.ai_format:
        print_report(result, verbose=args.verbose)
        print_recommendations_for_ai(result)
    else:
        print_report(result, verbose=args.verbose)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    sys.exit(0 if not result['errors'] else 1)


if __name__ == '__main__':
    main()
